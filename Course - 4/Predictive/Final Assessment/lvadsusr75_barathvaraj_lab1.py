# -*- coding: utf-8 -*-
"""LVADSUSR75_barathvaraj_lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l0HWmyTLgNdgAkJ106QX6GV5QAXcnVMO
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
import xgboost

df=pd.read_csv("/content/drive/MyDrive/pred_analysis_datasets/finalassess/loan_approval.csv")
df

df.info()
df.describe()

print(df.isna().sum())
print("No null values present")
print(df.columns)

numeric_values=df.drop([' education',' self_employed',' loan_status'],axis=1)
sns.boxplot(numeric_values)
plt.show()

from sklearn.ensemble import IsolationForest
iso=IsolationForest(contamination=0.02)
outliers=iso.fit_predict(numeric_values)
df_outliers=df.iloc[np.where(outliers==-1)]
df.drop(df_outliers.index,inplace=True)
df.info()

from sklearn.preprocessing import LabelEncoder, StandardScaler

le=LabelEncoder()
df[' education']=le.fit_transform(df[' education'])
df[' self_employed']=le.fit_transform(df[' self_employed'])
df[' loan_status']=le.fit_transform(df[' loan_status'])
df

X=df.drop([' loan_status'],axis=1)
y=df[' loan_status']
scaler=StandardScaler()
X_scaled=scaler.fit_transform(X)

X_train,X_test,y_train,y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)

lr=LogisticRegression()
rf=RandomForestClassifier()
dt=DecisionTreeClassifier()
xgb=xgboost.XGBClassifier()
svc=SVC()

lr.fit(X_train,y_train)
rf.fit(X_train,y_train)
dt.fit(X_train,y_train)
xgb.fit(X_train,y_train)
svc.fit(X_train,y_train)

y_pred_lr=lr.predict(X_test)
y_pred_rf=rf.predict(X_test)
y_pred_dt=dt.predict(X_test)
y_pred_xgb=xgb.predict(X_test)
y_pred_svc=svc.predict(X_test)

from sklearn.metrics import accuracy_score, confusion_matrix,classification_report

accuracy_score_lr=accuracy_score(y_test,y_pred_lr)
accuracy_score_rf=accuracy_score(y_test,y_pred_rf)
accuracy_score_dt=accuracy_score(y_test,y_pred_dt)
accuracy_score_xgb=accuracy_score(y_test,y_pred_xgb)
accuracy_score_svc=accuracy_score(y_test,y_pred_svc)

x_cols=['Logistic Regression','Random Forest','Decision Tree','XGBoost','SVC']
y_cols=[accuracy_score_lr,accuracy_score_rf,accuracy_score_dt,accuracy_score_xgb,accuracy_score_svc]

sns.barplot(x=y_cols, y=x_cols,orient='h')
plt.show()

print([(i,j) for i,j in zip(x_cols,y_cols)])

print("Decision tree has highest accuracy so decision tree is the best fit")

print("classification report: ",classification_report(y_test,y_pred_dt))
print("confusion matrix: ",confusion_matrix(y_test,y_pred_dt))